{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import requests\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from fiber import OCCURRENCE_INDEX\n",
    "from fiber.utils import Timer\n",
    "from fiber.cohort import Cohort\n",
    "from fiber.condition import MRNs, Diagnosis\n",
    "from fiber.extensions import BINARY_PIVOT_CONFIG\n",
    "from fiber.storage import yaml as fiber_yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slack_notification(i):\n",
    "    webhook_url = 'https://hooks.slack.com/services/xxxx/yyyy'\n",
    "    slack_data = {'text': f'Done {str(i)} occurrences'}\n",
    "\n",
    "    response = requests.post(\n",
    "        webhook_url, data=json.dumps(slack_data),\n",
    "        headers={'Content-Type': 'application/json'}\n",
    "    )\n",
    "    if response.status_code != 200:\n",
    "        raise ValueError(\n",
    "            'Request to slack returned an error %s, the response is:\\n%s'\n",
    "            % (response.status_code, response.text)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Feature Extraction\n",
    "\n",
    "This notebook executes the benchmark for the feature extraction for unsupervised machine learning.\n",
    "In this example, we create a cohort with patients that are diagnosed with complicated hypertension.\n",
    "\n",
    "The benchmark is run for up to 50,000 condition occurrences and reports the total runtimes, in-memory size of the final dataframe as well as the number of columns in the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypertension_cond = fiber_yaml.get_condition(\n",
    "    Diagnosis, \n",
    "    'hypertension complicated', \n",
    "    coding_schemes=['ICD-10']\n",
    ")\n",
    "hypertension_cohort = Cohort(hypertension_cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurrences = hypertension_cohort.get_occurrences(hypertension_cohort.condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurrences.sort_values(OCCURRENCE_INDEX, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_times = {}\n",
    "shapes = []\n",
    "size = []\n",
    "\n",
    "for limit in [100, 500, 1000, 5000, 10_000, 15_000, 20_000, 25_000, 30_000, 50_000]:\n",
    "    mrn_cond = MRNs(mrns=occurrences[:limit])\n",
    "    mrn_cohort = Cohort(mrn_cond)\n",
    "    with Timer('Total time: ') as t:\n",
    "        results = mrn_cohort.get_pivoted_features(pivot_config=BINARY_PIVOT_CONFIG, window=[-50, 50])\n",
    "    shapes.append(results.shape)\n",
    "    total_times[limit] = t.elapsed\n",
    "    size.append([limit, results.memory_usage(index=True, deep=True).sum()])\n",
    "    slack_notification(limit)\n",
    "slack_notification('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Persisting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimes = pd.DataFrame(list(total_times.items()), columns=['# Occurrences', 'Runtime in s'])\n",
    "features = pd.DataFrame(shapes, columns=['# Occurrences', '# Features'])\n",
    "sizes = pd.DataFrame(size, columns=['# Occurrences', 'Memory Consumption'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimes.to_csv('../results/unsupervised/runtimes.csv', index=False)\n",
    "features.to_csv('../results/unsupervised/features.csv', index=False)\n",
    "sizes.to_csv('../results/unsupervised/sizes.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features.plot.line(x='# Occurrences', y='# Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "runtimes.plot.line(x='# Occurrences', y='Runtime in s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes.plot.line(x='# Occurrences', y='Memory Consumption')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
